{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient descent exercises\n",
    "\n",
    "---\n",
    "These are introductory exercises in Machine learning with focus in **gradient descent** .\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> all datasets used in this exercise can be found under Data folder of the course Github repo</p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that in cases when you start to repeat code, try not to. Create functions to reuse code instead. </p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Remember</b> to use <b>descriptive variable, function, index </b> and <b> column names</b> in order to get readable code </p>\n",
    "\n",
    "The number of stars (\\*), (\\*\\*), (\\*\\*\\*) denotes the difficulty level of the task\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate dataset (*)\n",
    "\n",
    "Simulate datasets according to these rules:\n",
    "\n",
    "- set random seed to 42\n",
    "- (1000,2) samples from $X \\sim \\mathcal{U}(0,1)$ , i.e. 1000 rows, 2 columns. \n",
    "- 1000 samples from $\\epsilon \\sim \\mathcal{N}(0,1)$\n",
    "- $y = 3x_1 + 5x_2 + 3 + \\epsilon$ , where $x_i$ is column $i$ of $X$\n",
    "\n",
    "Finally add a column of ones for the intercept to $X$.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use for simulating X\n",
    "\n",
    "´´´\n",
    "np.random.rand(samples, 2)\n",
    "´´´\n",
    "\n",
    "to concatenate with ones, use ```np.c_[..., ...]```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "```\n",
    "array([[1.        , 0.37454012, 0.95071431],\n",
    "       [1.        , 0.73199394, 0.59865848],\n",
    "       [1.        , 0.15601864, 0.15599452],\n",
    "       [1.        , 0.05808361, 0.86617615],\n",
    "       [1.        , 0.60111501, 0.70807258]])\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42) # ensuring random numbers stay the same\n",
    "samples = 1000\n",
    "\n",
    "X = np.random.rand(samples, 2) # Crating X\n",
    "e = np.random.normal(0,1, size=(samples,1)) # creating noise\n",
    "\n",
    "y= 3*X[0] + 5*X[1] + 3 + e\n",
    "# TODO Need to ask about how to do this as a for loop instead\n",
    "\n",
    "X = np.c_[np.ones(samples), X] # using concat to add ones to the start of the array\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient descent - learning rate (*)\n",
    "\n",
    "Use gradient descent to calculate $\\vec{\\theta} = (\\theta_0, \\theta_1, \\theta_2)^T$ \n",
    "\n",
    "&nbsp; a) Use $\\eta = 0.1$ and calculate $\\vec{\\theta}$ for each fifth epoch from 1 to 500. So the procedure is as follows:\n",
    "- calculate $\\vec{\\theta}$ for epochs = 1\n",
    "- calculate $\\vec{\\theta}$ for epochs = 6\n",
    "- ...\n",
    "- calculate $\\vec{\\theta}$ for epochs = 496\n",
    "\n",
    "Plot these $\\vec{\\theta}$ values against epochs. (*)\n",
    "\n",
    "&nbsp; b) Do the same as for a) but with learning rate $\\eta = 0.01$, 5000 epochs and for each 20th epoch. What do you notice when changing the learning rate? (*)\n",
    "\n",
    "&nbsp; c) Experiment with larger and smaller $\\eta$ and see what happens.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a) \n",
    "\n",
    "<img src=\"../assets/grad_desc_converg.png\" height=\"200\"/>\n",
    "\n",
    "b) \n",
    "\n",
    "<img src=\"../assets/grad_desc_converg_001.png\" height=\"200\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-learning-NSZCLOcg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a14cf16dbe04b318d8bac1e80652bd6ae2f6a9de05db1fbb002c6e6ac9c8f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
