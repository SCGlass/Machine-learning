{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data = \"..\\data\\Heart_disease.csv\"\n",
    "df_disease = pd.read_csv(disease_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>bp_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55.38</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.93</td>\n",
       "      <td>obese (class I)</td>\n",
       "      <td>Stage 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>48.25</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.71</td>\n",
       "      <td>overweight</td>\n",
       "      <td>Stage 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>61.83</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.98</td>\n",
       "      <td>overweight</td>\n",
       "      <td>Stage 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>63.10</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>90.0</td>\n",
       "      <td>145</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.05</td>\n",
       "      <td>obese (class II)</td>\n",
       "      <td>Stage 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>60.07</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>82.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.40</td>\n",
       "      <td>overweight</td>\n",
       "      <td>Stage 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   1  55.38       1     156    85.0    140     90            3     1      0   \n",
       "1   3  48.25       2     169    82.0    150    100            1     1      0   \n",
       "2  12  61.83       2     178    95.0    130     90            3     3      0   \n",
       "3  32  63.10       1     158    90.0    145     85            2     2      0   \n",
       "4  46  60.07       2     173    82.0    140     90            3     1      0   \n",
       "\n",
       "   alco  active  cardio    BMI           BMI_cat bp_category  \n",
       "0     0       1       1  34.93   obese (class I)     Stage 2  \n",
       "1     0       1       1  28.71        overweight     Stage 2  \n",
       "2     0       1       1  29.98        overweight     Stage 1  \n",
       "3     0       1       1  36.05  obese (class II)     Stage 1  \n",
       "4     0       0       1  27.40        overweight     Stage 2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19788 entries, 0 to 19787\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           19788 non-null  int64  \n",
      " 1   age          19788 non-null  float64\n",
      " 2   gender       19788 non-null  int64  \n",
      " 3   height       19788 non-null  int64  \n",
      " 4   weight       19788 non-null  float64\n",
      " 5   ap_hi        19788 non-null  int64  \n",
      " 6   ap_lo        19788 non-null  int64  \n",
      " 7   cholesterol  19788 non-null  int64  \n",
      " 8   gluc         19788 non-null  int64  \n",
      " 9   smoke        19788 non-null  int64  \n",
      " 10  alco         19788 non-null  int64  \n",
      " 11  active       19788 non-null  int64  \n",
      " 12  cardio       19788 non-null  int64  \n",
      " 13  BMI          19788 non-null  float64\n",
      " 14  BMI_cat      19788 non-null  object \n",
      " 15  bp_category  19788 non-null  object \n",
      "dtypes: float64(3), int64(11), object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_disease.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>BMI_cat_normal range</th>\n",
       "      <th>BMI_cat_obese (class I)</th>\n",
       "      <th>BMI_cat_obese (class II)</th>\n",
       "      <th>BMI_cat_obese (class III)</th>\n",
       "      <th>BMI_cat_overweight</th>\n",
       "      <th>BMI_cat_underweight</th>\n",
       "      <th>bp_category_Elevated</th>\n",
       "      <th>bp_category_Healthy</th>\n",
       "      <th>bp_category_Stage 1</th>\n",
       "      <th>bp_category_Stage 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55.38</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  cholesterol  gluc  smoke  alco  active  cardio  female  male  \\\n",
       "0   1  55.38            3     1      0     0       1       1       1     0   \n",
       "\n",
       "   BMI_cat_normal range  BMI_cat_obese (class I)  BMI_cat_obese (class II)  \\\n",
       "0                     0                        1                         0   \n",
       "\n",
       "   BMI_cat_obese (class III)  BMI_cat_overweight  BMI_cat_underweight  \\\n",
       "0                          0                   0                    0   \n",
       "\n",
       "   bp_category_Elevated  bp_category_Healthy  bp_category_Stage 1  \\\n",
       "0                     0                    0                    0   \n",
       "\n",
       "   bp_category_Stage 2  \n",
       "0                    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = df_disease.drop(columns=[\"ap_hi\", \"ap_lo\", \"height\", \"weight\", \"BMI\"])\n",
    "df_one = pd.get_dummies(df_one, columns=[\"gender\",\"BMI_cat\", \"bp_category\"])\n",
    "df_one.rename(columns= {\"gender_1\" : \"female\", \"gender_2\" : \"male\"}, inplace=True)\n",
    "df_one.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55.38</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   1  55.38    140     90            3     1      0     0       1       1   \n",
       "\n",
       "     BMI  female  male  \n",
       "0  34.93       1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two = df_disease.drop(columns=[\"BMI_cat\", \"bp_category\", \"height\", \"weight\"])\n",
    "df_two = pd.get_dummies(df_two, columns=[\"gender\"])\n",
    "df_two.rename(columns= {\"gender_1\" : \"female\", \"gender_2\" : \"male\"}, inplace=True)\n",
    "df_two.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19788, 19), (19788,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train test split and validation for the first data frame\n",
    "X,y = df_one.drop(\"cardio\", axis = \"columns\"), df_one[\"cardio\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train = (13257, 19)\n",
      " X test = (3266, 19)\n",
      " X val = (3265, 19)\n",
      " y train = (13257,)\n",
      " y test = (3266,)\n",
      " y val = (3265,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"X train = {X_train.shape}\\n X test = {X_test.shape}\\n X val = {X_val.shape}\\n y train = {y_train.shape}\\n y test = {y_test.shape}\\n y val = {y_val.shape}\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling and normalization\n",
    "\n",
    "# creating a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# creating a MinMaxScaler object\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting and transforming the data using standard scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Fit and transforming the data using the minmax scaler\n",
    "X_train_norm = minmax_scaler.fit_transform(X_train)\n",
    "X_val_norm = minmax_scaler.transform(X_val)\n",
    "\n",
    "# TODO write a little more about the scalers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split the second datframe and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train = (13257, 12)\n",
      " X test = (3266, 12)\n",
      " X val = (3265, 12)\n",
      " y train = (13257,)\n",
      " y test = (3266,)\n",
      " y val = (3265,)\n"
     ]
    }
   ],
   "source": [
    "X2,y2 = df_two.drop(\"cardio\", axis = \"columns\"), df_two[\"cardio\"]\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X2, y2, test_size=0.33, random_state=42) \n",
    "X_val_2, X_test_2, y_val_2, y_test_2 = train_test_split(X_test_2, y_test_2, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# creating a MinMaxScaler object\n",
    "minmax_scaler = MinMaxScaler()\n",
    "# Fitting and transforming the data using standard scaler\n",
    "X_train_2_scaled = scaler.fit_transform(X_train_2)\n",
    "X_val_2_scaled = scaler.transform(X_val_2)\n",
    "# Fit and transforming the data using the minmax scaler\n",
    "X_train_2_norm = minmax_scaler.fit_transform(X_train_2)\n",
    "X_val_2_norm = minmax_scaler.transform(X_val_2)\n",
    "\n",
    "print(f\"X train = {X_train_2.shape}\\n X test = {X_test_2.shape}\\n X val = {X_val_2.shape}\\n y train = {y_train_2.shape}\\n y test = {y_test_2.shape}\\n y val = {y_val_2.shape}\"  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression Data set 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.65610717        nan        nan        nan 0.68039568\n",
      " 0.70589137 0.70453348 0.70589137 0.70589137 0.70596681 0.70589137\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70672051        nan        nan        nan 0.70853072\n",
      " 0.7062683  0.70596656 0.7062683  0.7062683  0.7062683  0.7062683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7061928         nan        nan        nan 0.70641916\n",
      " 0.70679638 0.70664549 0.70679638 0.70679638 0.70679638 0.70679638\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7065701         nan        nan        nan 0.70664552\n",
      " 0.70679638 0.70672096 0.70679638 0.70679638 0.70679638 0.70679638\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70672096        nan        nan        nan 0.70672096\n",
      " 0.70672096 0.70672096 0.70672096 0.70672096 0.70672096 0.70672096\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.80331899        nan        nan        nan 0.79266958\n",
      " 0.72480049 0.72833366 0.72480049 0.72480049 0.72485346 0.72480049\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.74009304        nan        nan        nan 0.73509849\n",
      " 0.7274861  0.72767204 0.7274861  0.7274861  0.7274861  0.7274861\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.72821502        nan        nan        nan 0.7279147\n",
      " 0.72805545 0.7279691  0.72805545 0.72805545 0.72805545 0.72805545\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.72792911        nan        nan        nan 0.72797074\n",
      " 0.72798324 0.72794168 0.72798324 0.72798324 0.72798324 0.72798324\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.72794168        nan        nan        nan 0.72794168\n",
      " 0.72794168 0.72794168 0.72794168 0.72794168 0.72794168 0.72794168\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.44080143        nan        nan        nan 0.51441251\n",
      " 0.69251741 0.68080931 0.69251741 0.69251741 0.69266372 0.69251741\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.66427236        nan        nan        nan 0.67934625\n",
      " 0.6879799  0.68666272 0.6879799  0.6879799  0.6879799  0.6879799\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.68622412        nan        nan        nan 0.68754141\n",
      " 0.68841935 0.68812653 0.68841935 0.68841935 0.68841935 0.68841935\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.68798033        nan        nan        nan 0.68812663\n",
      " 0.68856566 0.68841935 0.68856566 0.68856566 0.68856566 0.68856566\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.68841935        nan        nan        nan 0.68841935\n",
      " 0.68841935 0.68841935 0.68841935 0.68841935 0.68841935 0.68841935\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.56905617        nan        nan        nan 0.62380461\n",
      " 0.70818259 0.70367721 0.70818259 0.70818259 0.70827886 0.70818259\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70007133        nan        nan        nan 0.70603293\n",
      " 0.70706995 0.70645769 0.70706995 0.70706995 0.70706995 0.70706995\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70648947        nan        nan        nan 0.70705433\n",
      " 0.70758483 0.70738616 0.70758483 0.70758483 0.70758483 0.70758483\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70729106        nan        nan        nan 0.70738833\n",
      " 0.70762841 0.7075313  0.70762841 0.70762841 0.70762841 0.70762841\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7075313         nan        nan        nan 0.7075313\n",
      " 0.7075313  0.7075313  0.7075313  0.7075313  0.7075313  0.7075313\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00300035, 0.023383  , 0.00419879, 0.00240698, 0.00240006,\n",
      "       0.0971478 , 0.02918091, 0.05736656, 0.09354596, 0.0245862 ,\n",
      "       0.07555242, 0.08556328, 0.00340443, 0.00340042, 0.00438933,\n",
      "       0.00319505, 0.00279841, 0.00519791, 0.00299921, 0.00140066,\n",
      "       0.00459924, 0.00399623, 0.00399928, 0.00259933, 0.00399923,\n",
      "       0.1273272 , 0.00339866, 0.00259867, 0.00459738, 0.20808415,\n",
      "       0.02558789, 0.05996566, 0.12373018, 0.03597913, 0.11833935,\n",
      "       0.09534674, 0.00259976, 0.00239944, 0.00200453, 0.00260763,\n",
      "       0.00260038, 0.00500517, 0.00259962, 0.0047977 , 0.00179987,\n",
      "       0.0020009 , 0.00140047, 0.00199962, 0.00220022, 0.0739491 ,\n",
      "       0.00260315, 0.00260367, 0.00260696, 0.68280067, 0.02458944,\n",
      "       0.03937712, 0.09694386, 0.03118243, 0.15391908, 0.08994875,\n",
      "       0.00260839, 0.00299935, 0.00239935, 0.00220995, 0.00319982,\n",
      "       0.00519805, 0.00239882, 0.00240779, 0.00240841, 0.00221272,\n",
      "       0.00239506, 0.00199685, 0.00320702, 0.44034204, 0.00240068,\n",
      "       0.002808  , 0.00241241, 0.26264868, 0.02018933, 0.03237591,\n",
      "       0.09474516, 0.02318859, 0.30302625, 0.12692742, 0.00359969,\n",
      "       0.00240026, 0.00300078, 0.00379982, 0.00279956, 0.00619831,\n",
      "       0.002001  , 0.00339956, 0.00259986, 0.00319848, 0.00399861,\n",
      "       0.00299859, 0.00420251, 0.03338075, 0.00339761, 0.00379877,\n",
      "       0.00319991, 0.83391685, 0.01958938, 0.03957524, 0.08348002,\n",
      "       0.02379227, 0.14312921, 0.11373034, 0.00260315, 0.00220742,\n",
      "       0.0023973 , 0.00260019, 0.00300188, 0.00480928, 0.00240169,\n",
      "       0.00181012, 0.00221786, 0.00179687, 0.00180073, 0.00220008]), 'std_fit_time': array([8.92870195e-04, 2.72867981e-03, 2.31460433e-03, 4.89958698e-04,\n",
      "       7.99330800e-04, 3.80538920e-03, 8.83891608e-03, 1.32522952e-02,\n",
      "       3.82847538e-02, 2.05870393e-03, 8.94551000e-03, 9.41250595e-03,\n",
      "       1.73964778e-03, 1.35712168e-03, 1.01344208e-03, 1.16296737e-03,\n",
      "       7.46697295e-04, 1.46923756e-03, 8.92176934e-04, 8.01110543e-04,\n",
      "       2.86786430e-03, 2.09596647e-03, 2.75612606e-03, 1.85353522e-03,\n",
      "       1.78760560e-03, 6.56536594e-02, 1.49691191e-03, 4.89609804e-04,\n",
      "       2.15293174e-03, 1.18265206e-01, 2.24224315e-03, 1.03458222e-02,\n",
      "       1.50304810e-02, 1.36142699e-02, 3.35844869e-02, 1.00261094e-02,\n",
      "       7.99322818e-04, 7.98702710e-04, 8.68524557e-06, 8.03244505e-04,\n",
      "       7.89174132e-04, 8.93196537e-04, 2.24477672e-03, 1.93597646e-03,\n",
      "       7.46365809e-04, 1.09345142e-03, 7.99655957e-04, 6.31655854e-04,\n",
      "       3.98948156e-04, 1.40797367e-02, 7.87099262e-04, 1.18728699e-03,\n",
      "       8.04164861e-04, 4.58967879e-02, 5.11826044e-03, 5.46068587e-03,\n",
      "       9.05055307e-03, 2.71177224e-03, 2.05836538e-02, 8.65862353e-03,\n",
      "       7.93977665e-04, 1.09575774e-03, 8.00538423e-04, 4.03683095e-04,\n",
      "       7.47292327e-04, 1.59155006e-03, 7.94008148e-04, 7.85984329e-04,\n",
      "       1.01283568e-03, 4.04959425e-04, 7.91479010e-04, 6.25491305e-04,\n",
      "       1.16030978e-03, 1.60410482e-01, 7.99633400e-04, 7.49445852e-04,\n",
      "       7.94539601e-04, 2.78476588e-02, 1.46947025e-03, 3.26308258e-03,\n",
      "       1.85626201e-02, 1.16618250e-03, 2.79225769e-02, 2.77835418e-02,\n",
      "       7.98250019e-04, 7.98536819e-04, 8.94309843e-04, 1.93638383e-03,\n",
      "       7.47071618e-04, 7.48482731e-04, 6.31580589e-04, 4.89241440e-04,\n",
      "       7.98417633e-04, 7.48176079e-04, 8.95059452e-04, 6.31580563e-04,\n",
      "       1.16573191e-03, 7.08210398e-03, 1.20090705e-03, 1.16549269e-03,\n",
      "       7.47285247e-04, 9.79963233e-02, 4.88130129e-04, 6.24105329e-03,\n",
      "       5.73435014e-03, 7.44419625e-04, 1.93607139e-02, 3.41041764e-02,\n",
      "       4.92563751e-04, 3.94750919e-04, 7.91789573e-04, 4.89110285e-04,\n",
      "       8.99470640e-04, 7.39655263e-04, 1.02071910e-03, 7.55777260e-04,\n",
      "       9.80674765e-04, 7.40672964e-04, 7.47742477e-04, 7.48601254e-04]), 'mean_score_time': array([0.        , 0.01399436, 0.        , 0.        , 0.        ,\n",
      "       0.01438751, 0.02078643, 0.03777804, 0.01179404, 0.01239305,\n",
      "       0.01299624, 0.01258821, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.01978836, 0.        , 0.        , 0.        , 0.01599135,\n",
      "       0.01558838, 0.03358102, 0.01918736, 0.02038579, 0.01519189,\n",
      "       0.01419549, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.01319966,\n",
      "       0.        , 0.        , 0.        , 0.01200519, 0.01638765,\n",
      "       0.01419144, 0.0145925 , 0.0157908 , 0.01358771, 0.01239691,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.01339302, 0.        ,\n",
      "       0.        , 0.        , 0.01619611, 0.0145906 , 0.01399283,\n",
      "       0.01139317, 0.01219172, 0.02518654, 0.01519132, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.01499095, 0.        , 0.        ,\n",
      "       0.        , 0.01320095, 0.01279607, 0.0137948 , 0.01219201,\n",
      "       0.01219664, 0.01239414, 0.01339784, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), 'std_score_time': array([0.        , 0.0008985 , 0.        , 0.        , 0.        ,\n",
      "       0.00206304, 0.00696012, 0.03603285, 0.00193959, 0.00101972,\n",
      "       0.00063283, 0.00148024, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00425953, 0.        , 0.        , 0.        , 0.00141246,\n",
      "       0.00149904, 0.01346304, 0.00292311, 0.00265255, 0.00517863,\n",
      "       0.00438363, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00192964,\n",
      "       0.        , 0.        , 0.        , 0.00126049, 0.00272915,\n",
      "       0.0013233 , 0.0040284 , 0.00097832, 0.00294276, 0.00161677,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00119985, 0.        ,\n",
      "       0.        , 0.        , 0.00526385, 0.0037733 , 0.00154687,\n",
      "       0.00048951, 0.00116472, 0.00518957, 0.00193767, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00227889, 0.        , 0.        ,\n",
      "       0.        , 0.00159878, 0.00074383, 0.00213111, 0.00171953,\n",
      "       0.0028503 , 0.00134163, 0.00313121, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n",
      "                   'l2', 'l2', 'l2', 'elasticnet', 'elasticnet',\n",
      "                   'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'l1',\n",
      "                   'l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
      "                   'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
      "                   'elasticnet', 'elasticnet', 'elasticnet', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'l1', 'l1',\n",
      "                   'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
      "                   'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
      "                   'elasticnet', 'elasticnet', 'elasticnet', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'l1', 'l1',\n",
      "                   'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
      "                   'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
      "                   'elasticnet', 'elasticnet', 'elasticnet', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'l1', 'l1',\n",
      "                   'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
      "                   'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
      "                   'elasticnet', 'elasticnet', 'elasticnet', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky',\n",
      "                   'sag', 'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga', 'lbfgs', 'liblinear',\n",
      "                   'newton-cg', 'newton-cholesky', 'sag', 'saga', 'lbfgs',\n",
      "                   'liblinear', 'newton-cg', 'newton-cholesky', 'sag',\n",
      "                   'saga', 'lbfgs', 'liblinear', 'newton-cg',\n",
      "                   'newton-cholesky', 'sag', 'saga'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}, {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}, {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}, {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}, {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}, {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}, {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}, {'C': 0.001, 'penalty': 'None', 'solver': 'lbfgs'}, {'C': 0.001, 'penalty': 'None', 'solver': 'liblinear'}, {'C': 0.001, 'penalty': 'None', 'solver': 'newton-cg'}, {'C': 0.001, 'penalty': 'None', 'solver': 'newton-cholesky'}, {'C': 0.001, 'penalty': 'None', 'solver': 'sag'}, {'C': 0.001, 'penalty': 'None', 'solver': 'saga'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cholesky'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'sag'}, {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cholesky'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}, {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'sag'}, {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'saga'}, {'C': 0.01, 'penalty': 'None', 'solver': 'lbfgs'}, {'C': 0.01, 'penalty': 'None', 'solver': 'liblinear'}, {'C': 0.01, 'penalty': 'None', 'solver': 'newton-cg'}, {'C': 0.01, 'penalty': 'None', 'solver': 'newton-cholesky'}, {'C': 0.01, 'penalty': 'None', 'solver': 'sag'}, {'C': 0.01, 'penalty': 'None', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cholesky'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cholesky'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'}, {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'None', 'solver': 'lbfgs'}, {'C': 0.1, 'penalty': 'None', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'None', 'solver': 'newton-cg'}, {'C': 0.1, 'penalty': 'None', 'solver': 'newton-cholesky'}, {'C': 0.1, 'penalty': 'None', 'solver': 'sag'}, {'C': 0.1, 'penalty': 'None', 'solver': 'saga'}, {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}, {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}, {'C': 1, 'penalty': 'l1', 'solver': 'newton-cholesky'}, {'C': 1, 'penalty': 'l1', 'solver': 'sag'}, {'C': 1, 'penalty': 'l1', 'solver': 'saga'}, {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}, {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'C': 1, 'penalty': 'l2', 'solver': 'newton-cholesky'}, {'C': 1, 'penalty': 'l2', 'solver': 'sag'}, {'C': 1, 'penalty': 'l2', 'solver': 'saga'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'sag'}, {'C': 1, 'penalty': 'elasticnet', 'solver': 'saga'}, {'C': 1, 'penalty': 'None', 'solver': 'lbfgs'}, {'C': 1, 'penalty': 'None', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'None', 'solver': 'newton-cg'}, {'C': 1, 'penalty': 'None', 'solver': 'newton-cholesky'}, {'C': 1, 'penalty': 'None', 'solver': 'sag'}, {'C': 1, 'penalty': 'None', 'solver': 'saga'}, {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}, {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}, {'C': 10, 'penalty': 'l1', 'solver': 'newton-cholesky'}, {'C': 10, 'penalty': 'l1', 'solver': 'sag'}, {'C': 10, 'penalty': 'l1', 'solver': 'saga'}, {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}, {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}, {'C': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}, {'C': 10, 'penalty': 'l2', 'solver': 'sag'}, {'C': 10, 'penalty': 'l2', 'solver': 'saga'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'}, {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'}, {'C': 10, 'penalty': 'None', 'solver': 'lbfgs'}, {'C': 10, 'penalty': 'None', 'solver': 'liblinear'}, {'C': 10, 'penalty': 'None', 'solver': 'newton-cg'}, {'C': 10, 'penalty': 'None', 'solver': 'newton-cholesky'}, {'C': 10, 'penalty': 'None', 'solver': 'sag'}, {'C': 10, 'penalty': 'None', 'solver': 'saga'}], 'split0_test_accuracy': array([       nan, 0.64027149,        nan,        nan,        nan,\n",
      "       0.66704374, 0.7066365 , 0.70588235, 0.7066365 , 0.7066365 ,\n",
      "       0.7066365 , 0.7066365 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.70701357,        nan,        nan,        nan, 0.70927602,\n",
      "       0.71040724, 0.70965309, 0.71040724, 0.71040724, 0.71040724,\n",
      "       0.71040724,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.70965309,\n",
      "              nan,        nan,        nan, 0.70965309, 0.71040724,\n",
      "       0.71040724, 0.71040724, 0.71040724, 0.71040724, 0.71040724,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70965309,        nan,\n",
      "              nan,        nan, 0.71003017, 0.71040724, 0.71003017,\n",
      "       0.71040724, 0.71040724, 0.71040724, 0.71040724,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.71003017,        nan,        nan,\n",
      "              nan, 0.71003017, 0.71003017, 0.71003017, 0.71003017,\n",
      "       0.71003017, 0.71003017, 0.71003017,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_accuracy': array([       nan, 0.65912519,        nan,        nan,        nan,\n",
      "       0.68815988, 0.70324284, 0.70286576, 0.70324284, 0.70324284,\n",
      "       0.70324284, 0.70324284,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.71266968,        nan,        nan,        nan, 0.71606335,\n",
      "       0.70324284, 0.70361991, 0.70324284, 0.70324284, 0.70324284,\n",
      "       0.70324284,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.70475113,\n",
      "              nan,        nan,        nan, 0.70437406, 0.70361991,\n",
      "       0.70361991, 0.70361991, 0.70361991, 0.70361991, 0.70361991,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70361991,        nan,\n",
      "              nan,        nan, 0.70361991, 0.70361991, 0.70361991,\n",
      "       0.70361991, 0.70361991, 0.70361991, 0.70361991,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.70361991,        nan,        nan,\n",
      "              nan, 0.70361991, 0.70361991, 0.70361991, 0.70361991,\n",
      "       0.70361991, 0.70361991, 0.70361991,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_accuracy': array([       nan, 0.66691814,        nan,        nan,        nan,\n",
      "       0.69294606, 0.7197284 , 0.71859676, 0.7197284 , 0.7197284 ,\n",
      "       0.72010562, 0.7197284 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.71633346,        nan,        nan,        nan, 0.71935119,\n",
      "       0.71935119, 0.71935119, 0.71935119, 0.71935119, 0.71935119,\n",
      "       0.71935119,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.71821954,\n",
      "              nan,        nan,        nan, 0.71859676, 0.71821954,\n",
      "       0.71821954, 0.71821954, 0.71821954, 0.71821954, 0.71821954,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.71821954,        nan,\n",
      "              nan,        nan, 0.71821954, 0.71821954, 0.71821954,\n",
      "       0.71821954, 0.71821954, 0.71821954, 0.71821954,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.71821954,        nan,        nan,\n",
      "              nan, 0.71821954, 0.71821954, 0.71821954, 0.71821954,\n",
      "       0.71821954, 0.71821954, 0.71821954,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split3_test_accuracy': array([       nan, 0.65069785,        nan,        nan,        nan,\n",
      "       0.66804979, 0.69898152, 0.69671822, 0.69898152, 0.69898152,\n",
      "       0.69898152, 0.69898152,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.69671822,        nan,        nan,        nan, 0.69558657,\n",
      "       0.69935873, 0.69973595, 0.69935873, 0.69935873, 0.69935873,\n",
      "       0.69935873,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.69898152,\n",
      "              nan,        nan,        nan, 0.70049038, 0.70199925,\n",
      "       0.70124481, 0.70199925, 0.70199925, 0.70199925, 0.70199925,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70162203,        nan,\n",
      "              nan,        nan, 0.70162203, 0.70199925, 0.70199925,\n",
      "       0.70199925, 0.70199925, 0.70199925, 0.70199925,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.70199925,        nan,        nan,\n",
      "              nan, 0.70199925, 0.70199925, 0.70199925, 0.70199925,\n",
      "       0.70199925, 0.70199925, 0.70199925,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split4_test_accuracy': array([       nan, 0.6635232 ,        nan,        nan,        nan,\n",
      "       0.68577895, 0.7008676 , 0.6986043 , 0.7008676 , 0.7008676 ,\n",
      "       0.7008676 , 0.7008676 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.7008676 ,        nan,        nan,        nan, 0.70237646,\n",
      "       0.69898152, 0.69747265, 0.69898152, 0.69898152, 0.69898152,\n",
      "       0.69898152,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.69935873,\n",
      "              nan,        nan,        nan, 0.69898152, 0.69973595,\n",
      "       0.69973595, 0.69973595, 0.69973595, 0.69973595, 0.69973595,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.69973595,        nan,\n",
      "              nan,        nan, 0.69973595, 0.69973595, 0.69973595,\n",
      "       0.69973595, 0.69973595, 0.69973595, 0.69973595,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.69973595,        nan,        nan,\n",
      "              nan, 0.69973595, 0.69973595, 0.69973595, 0.69973595,\n",
      "       0.69973595, 0.69973595, 0.69973595,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_accuracy': array([       nan, 0.65610717,        nan,        nan,        nan,\n",
      "       0.68039568, 0.70589137, 0.70453348, 0.70589137, 0.70589137,\n",
      "       0.70596681, 0.70589137,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.70672051,        nan,        nan,        nan, 0.70853072,\n",
      "       0.7062683 , 0.70596656, 0.7062683 , 0.7062683 , 0.7062683 ,\n",
      "       0.7062683 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.7061928 ,\n",
      "              nan,        nan,        nan, 0.70641916, 0.70679638,\n",
      "       0.70664549, 0.70679638, 0.70679638, 0.70679638, 0.70679638,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.7065701 ,        nan,\n",
      "              nan,        nan, 0.70664552, 0.70679638, 0.70672096,\n",
      "       0.70679638, 0.70679638, 0.70679638, 0.70679638,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.70672096,        nan,        nan,\n",
      "              nan, 0.70672096, 0.70672096, 0.70672096, 0.70672096,\n",
      "       0.70672096, 0.70672096, 0.70672096,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_accuracy': array([       nan, 0.00960221,        nan,        nan,        nan,\n",
      "       0.01074681, 0.00737588, 0.007728  , 0.00737588, 0.00737588,\n",
      "       0.00751759, 0.00737588,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00724141,        nan,        nan,        nan, 0.00871555,\n",
      "       0.0077238 , 0.007864  , 0.0077238 , 0.0077238 , 0.0077238 ,\n",
      "       0.0077238 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.00717498,\n",
      "              nan,        nan,        nan, 0.00711904, 0.00673022,\n",
      "       0.00684358, 0.00673022, 0.00673022, 0.00673022, 0.00673022,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.0067098 ,        nan,\n",
      "              nan,        nan, 0.00674605, 0.00673022, 0.00669133,\n",
      "       0.00673022, 0.00673022, 0.00673022, 0.00673022,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.00669133,        nan,        nan,\n",
      "              nan, 0.00669133, 0.00669133, 0.00669133, 0.00669133,\n",
      "       0.00669133, 0.00669133, 0.00669133,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_accuracy': array([41, 40, 41, 41, 41, 39, 34, 38, 34, 34, 32, 34, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 21, 41, 41, 41,  1, 26, 33, 26, 26,\n",
      "       26, 26, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 31, 41,\n",
      "       41, 41, 25,  2, 23,  2,  2,  2,  2, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 24, 41, 41, 41, 22,  2, 12,  2,  2,  2,  2, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 12, 41, 41, 41, 12,\n",
      "       12, 12, 12, 12, 12, 12, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41]), 'split0_test_precision': array([       nan, 0.79043601,        nan,        nan,        nan,\n",
      "       0.78009259, 0.7256705 , 0.73092054, 0.7256705 , 0.7256705 ,\n",
      "       0.7256705 , 0.7256705 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.74180328,        nan,        nan,        nan, 0.73954984,\n",
      "       0.73307393, 0.73302108, 0.73307393, 0.73307393, 0.73307393,\n",
      "       0.73307393,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.73338546,\n",
      "              nan,        nan,        nan, 0.73302108, 0.73271173,\n",
      "       0.73271173, 0.73271173, 0.73271173, 0.73271173, 0.73271173,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.73229572,        nan,\n",
      "              nan,        nan, 0.73250389, 0.73235066, 0.73214286,\n",
      "       0.73235066, 0.73235066, 0.73235066, 0.73235066,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.73214286,        nan,        nan,\n",
      "              nan, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
      "       0.73214286, 0.73214286, 0.73214286,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_precision': array([       nan, 0.79490446,        nan,        nan,        nan,\n",
      "       0.79032258, 0.7119883 , 0.71685393, 0.7119883 , 0.7119883 ,\n",
      "       0.71167883, 0.7119883 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.73800157,        nan,        nan,        nan, 0.73292868,\n",
      "       0.71418021, 0.71470806, 0.71418021, 0.71418021, 0.71418021,\n",
      "       0.71418021,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.71661721,\n",
      "              nan,        nan,        nan, 0.71608599, 0.7153447 ,\n",
      "       0.7153447 , 0.7153447 , 0.7153447 , 0.7153447 , 0.7153447 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.7153447 ,        nan,\n",
      "              nan,        nan, 0.7153447 , 0.7153447 , 0.7153447 ,\n",
      "       0.7153447 , 0.7153447 , 0.7153447 , 0.7153447 ,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.7153447 ,        nan,        nan,\n",
      "              nan, 0.7153447 , 0.7153447 , 0.7153447 , 0.7153447 ,\n",
      "       0.7153447 , 0.7153447 , 0.7153447 ,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_precision': array([       nan, 0.81428571,        nan,        nan,        nan,\n",
      "       0.80688124, 0.74148607, 0.74391202, 0.74148607, 0.74148607,\n",
      "       0.74206042, 0.74148607,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.75184275,        nan,        nan,        nan, 0.7490008 ,\n",
      "       0.74091261, 0.7416602 , 0.74091261, 0.74091261, 0.74091261,\n",
      "       0.74091261,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.74143302,\n",
      "              nan,        nan,        nan, 0.74088441, 0.73956723,\n",
      "       0.73956723, 0.73956723, 0.73956723, 0.73956723, 0.73956723,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.73956723,        nan,\n",
      "              nan,        nan, 0.73956723, 0.73956723, 0.73956723,\n",
      "       0.73956723, 0.73956723, 0.73956723, 0.73956723,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.73956723,        nan,        nan,\n",
      "              nan, 0.73956723, 0.73956723, 0.73956723, 0.73956723,\n",
      "       0.73956723, 0.73956723, 0.73956723,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split3_test_precision': array([       nan, 0.78871391,        nan,        nan,        nan,\n",
      "       0.77866972, 0.72362205, 0.72516026, 0.72362205, 0.72362205,\n",
      "       0.72362205, 0.72362205,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.7345576 ,        nan,        nan,        nan, 0.72594988,\n",
      "       0.72669323, 0.72727273, 0.72669323, 0.72669323, 0.72669323,\n",
      "       0.72669323,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.7272    ,\n",
      "              nan,        nan,        nan, 0.72770701, 0.72929936,\n",
      "       0.72886762, 0.72929936, 0.72929936, 0.72929936, 0.72929936,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.72908367,        nan,\n",
      "              nan,        nan, 0.72908367, 0.72929936, 0.72929936,\n",
      "       0.72929936, 0.72929936, 0.72929936, 0.72929936,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.72929936,        nan,        nan,\n",
      "              nan, 0.72929936, 0.72929936, 0.72929936, 0.72929936,\n",
      "       0.72929936, 0.72929936, 0.72929936,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split4_test_precision': array([       nan, 0.82825485,        nan,        nan,        nan,\n",
      "       0.80738178, 0.72123552, 0.72482157, 0.72123552, 0.72123552,\n",
      "       0.72123552, 0.72123552,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.73426002,        nan,        nan,        nan, 0.72806324,\n",
      "       0.72257053, 0.72169811, 0.72257053, 0.72257053, 0.72257053,\n",
      "       0.72257053,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.72243941,\n",
      "              nan,        nan,        nan, 0.721875  , 0.72335423,\n",
      "       0.72335423, 0.72335423, 0.72335423, 0.72335423, 0.72335423,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.72335423,        nan,\n",
      "              nan,        nan, 0.72335423, 0.72335423, 0.72335423,\n",
      "       0.72335423, 0.72335423, 0.72335423, 0.72335423,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.72335423,        nan,        nan,\n",
      "              nan, 0.72335423, 0.72335423, 0.72335423, 0.72335423,\n",
      "       0.72335423, 0.72335423, 0.72335423,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_precision': array([       nan, 0.80331899,        nan,        nan,        nan,\n",
      "       0.79266958, 0.72480049, 0.72833366, 0.72480049, 0.72480049,\n",
      "       0.72485346, 0.72480049,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.74009304,        nan,        nan,        nan, 0.73509849,\n",
      "       0.7274861 , 0.72767204, 0.7274861 , 0.7274861 , 0.7274861 ,\n",
      "       0.7274861 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.72821502,\n",
      "              nan,        nan,        nan, 0.7279147 , 0.72805545,\n",
      "       0.7279691 , 0.72805545, 0.72805545, 0.72805545, 0.72805545,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.72792911,        nan,\n",
      "              nan,        nan, 0.72797074, 0.72798324, 0.72794168,\n",
      "       0.72798324, 0.72798324, 0.72798324, 0.72798324,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.72794168,        nan,        nan,\n",
      "              nan, 0.72794168, 0.72794168, 0.72794168, 0.72794168,\n",
      "       0.72794168, 0.72794168, 0.72794168,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_precision': array([       nan, 0.01544118,        nan,        nan,        nan,\n",
      "       0.01247482, 0.00956468, 0.00898406, 0.00956468, 0.00956468,\n",
      "       0.00984808, 0.00956468,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00648105,        nan,        nan,        nan, 0.00837841,\n",
      "       0.00909212, 0.00925411, 0.00909212, 0.00909212, 0.00909212,\n",
      "       0.00909212,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.00860635,\n",
      "              nan,        nan,        nan, 0.00861078, 0.0082391 ,\n",
      "       0.00822787, 0.0082391 , 0.0082391 , 0.0082391 , 0.0082391 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.0081871 ,        nan,\n",
      "              nan,        nan, 0.0082097 , 0.00819946, 0.00817772,\n",
      "       0.00819946, 0.00819946, 0.00819946, 0.00819946,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.00817772,        nan,        nan,\n",
      "              nan, 0.00817772, 0.00817772, 0.00817772, 0.00817772,\n",
      "       0.00817772, 0.00817772, 0.00817772,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_precision': array([41,  1, 41, 41, 41,  2, 37,  5, 37, 37, 36, 37, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41,  3, 41, 41, 41,  4, 31, 30, 31, 31,\n",
      "       31, 31, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,  6, 41,\n",
      "       41, 41, 29,  7, 18,  7,  7,  7,  7, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 28, 41, 41, 41, 17, 12, 19, 12, 12, 12, 12, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 19, 41, 41, 41, 19,\n",
      "       19, 19, 19, 19, 19, 19, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41]), 'split0_test_recall': array([       nan, 0.41111924,        nan,        nan,        nan,\n",
      "       0.49305048, 0.69275786, 0.67959034, 0.69275786, 0.69275786,\n",
      "       0.69275786, 0.69275786,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.66203365,        nan,        nan,        nan, 0.67300658,\n",
      "       0.68910022, 0.68690563, 0.68910022, 0.68910022, 0.68910022,\n",
      "       0.68910022,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.6861741 ,\n",
      "              nan,        nan,        nan, 0.68690563, 0.68983175,\n",
      "       0.68983175, 0.68983175, 0.68983175, 0.68983175, 0.68983175,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.68836869,        nan,\n",
      "              nan,        nan, 0.68910022, 0.69056328, 0.68983175,\n",
      "       0.69056328, 0.69056328, 0.69056328, 0.69056328,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.68983175,        nan,        nan,\n",
      "              nan, 0.68983175, 0.68983175, 0.68983175, 0.68983175,\n",
      "       0.68983175, 0.68983175, 0.68983175,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_recall': array([       nan, 0.45647403,        nan,        nan,        nan,\n",
      "       0.53767374, 0.71250914, 0.70007315, 0.71250914, 0.71250914,\n",
      "       0.71324067, 0.71250914,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.6861741 ,        nan,        nan,        nan, 0.70665691,\n",
      "       0.70738844, 0.70738844, 0.70738844, 0.70738844, 0.70738844,\n",
      "       0.70738844,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.70665691,\n",
      "              nan,        nan,        nan, 0.70665691, 0.70592538,\n",
      "       0.70592538, 0.70592538, 0.70592538, 0.70592538, 0.70592538,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70592538,        nan,\n",
      "              nan,        nan, 0.70592538, 0.70592538, 0.70592538,\n",
      "       0.70592538, 0.70592538, 0.70592538, 0.70592538,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.70592538,        nan,        nan,\n",
      "              nan, 0.70592538, 0.70592538, 0.70592538, 0.70592538,\n",
      "       0.70592538, 0.70592538, 0.70592538,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_recall': array([       nan, 0.45866862,        nan,        nan,        nan,\n",
      "       0.53182151, 0.70080468, 0.69275786, 0.70080468, 0.70080468,\n",
      "       0.70080468, 0.70080468,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.67154353,        nan,        nan,        nan, 0.68544257,\n",
      "       0.70080468, 0.69934162, 0.70080468, 0.70080468, 0.70080468,\n",
      "       0.70080468,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.69641551,\n",
      "              nan,        nan,        nan, 0.6986101 , 0.70007315,\n",
      "       0.70007315, 0.70007315, 0.70007315, 0.70007315, 0.70007315,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70007315,        nan,\n",
      "              nan,        nan, 0.70007315, 0.70007315, 0.70007315,\n",
      "       0.70007315, 0.70007315, 0.70007315, 0.70007315,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.70007315,        nan,        nan,\n",
      "              nan, 0.70007315, 0.70007315, 0.70007315, 0.70007315,\n",
      "       0.70007315, 0.70007315, 0.70007315,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split3_test_recall': array([       nan, 0.43997072,        nan,        nan,        nan,\n",
      "       0.49707174, 0.6727672 , 0.6625183 , 0.6727672 , 0.6727672 ,\n",
      "       0.6727672 , 0.6727672 ,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.64421669,        nan,        nan,        nan, 0.65739385,\n",
      "       0.66764275, 0.66764275, 0.66764275, 0.66764275, 0.66764275,\n",
      "       0.66764275,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.66544656,\n",
      "              nan,        nan,        nan, 0.66910688, 0.67057101,\n",
      "       0.66910688, 0.67057101, 0.67057101, 0.67057101, 0.67057101,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.66983895,        nan,\n",
      "              nan,        nan, 0.66983895, 0.67057101, 0.67057101,\n",
      "       0.67057101, 0.67057101, 0.67057101, 0.67057101,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.67057101,        nan,        nan,\n",
      "              nan, 0.67057101, 0.67057101, 0.67057101, 0.67057101,\n",
      "       0.67057101, 0.67057101, 0.67057101,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split4_test_recall': array([       nan, 0.43777452,        nan,        nan,        nan,\n",
      "       0.5124451 , 0.68374817, 0.66910688, 0.68374817, 0.68374817,\n",
      "       0.68374817, 0.68374817,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.65739385,        nan,        nan,        nan, 0.67423133,\n",
      "       0.6749634 , 0.67203514, 0.6749634 , 0.6749634 , 0.6749634 ,\n",
      "       0.6749634 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.67642753,\n",
      "              nan,        nan,        nan, 0.67642753, 0.67569546,\n",
      "       0.67569546, 0.67569546, 0.67569546, 0.67569546, 0.67569546,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.67569546,        nan,\n",
      "              nan,        nan, 0.67569546, 0.67569546, 0.67569546,\n",
      "       0.67569546, 0.67569546, 0.67569546, 0.67569546,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.67569546,        nan,        nan,\n",
      "              nan, 0.67569546, 0.67569546, 0.67569546, 0.67569546,\n",
      "       0.67569546, 0.67569546, 0.67569546,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_recall': array([       nan, 0.44080143,        nan,        nan,        nan,\n",
      "       0.51441251, 0.69251741, 0.68080931, 0.69251741, 0.69251741,\n",
      "       0.69266372, 0.69251741,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.66427236,        nan,        nan,        nan, 0.67934625,\n",
      "       0.6879799 , 0.68666272, 0.6879799 , 0.6879799 , 0.6879799 ,\n",
      "       0.6879799 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.68622412,\n",
      "              nan,        nan,        nan, 0.68754141, 0.68841935,\n",
      "       0.68812653, 0.68841935, 0.68841935, 0.68841935, 0.68841935,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.68798033,        nan,\n",
      "              nan,        nan, 0.68812663, 0.68856566, 0.68841935,\n",
      "       0.68856566, 0.68856566, 0.68856566, 0.68856566,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.68841935,        nan,        nan,\n",
      "              nan, 0.68841935, 0.68841935, 0.68841935, 0.68841935,\n",
      "       0.68841935, 0.68841935, 0.68841935,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_recall': array([       nan, 0.01706313,        nan,        nan,        nan,\n",
      "       0.01791685, 0.01367755, 0.0140489 , 0.01367755, 0.01367755,\n",
      "       0.01389283, 0.01367755,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.01405071,        nan,        nan,        nan, 0.01631747,\n",
      "       0.015003  , 0.01527151, 0.015003  , 0.015003  , 0.015003  ,\n",
      "       0.015003  ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.01448479,\n",
      "              nan,        nan,        nan, 0.01379618, 0.01359947,\n",
      "       0.01399076, 0.01359947, 0.01359947, 0.01359947, 0.01359947,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.01377273,        nan,\n",
      "              nan,        nan, 0.01377996, 0.0136178 , 0.01359947,\n",
      "       0.0136178 , 0.0136178 , 0.0136178 , 0.0136178 ,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.01359947,        nan,        nan,\n",
      "              nan, 0.01359947, 0.01359947, 0.01359947, 0.01359947,\n",
      "       0.01359947, 0.01359947, 0.01359947,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_recall': array([41, 40, 41, 41, 41, 39,  2, 36,  2,  2,  1,  2, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 38, 41, 41, 41, 37, 28, 34, 28, 28,\n",
      "       28, 28, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 35, 41,\n",
      "       41, 41, 33, 11, 26, 11, 11, 11, 11, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 27, 41, 41, 41, 25,  6, 11,  6,  6,  6,  6, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 11, 41, 41, 41, 11,\n",
      "       11, 11, 11, 11, 11, 11, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41]), 'split0_test_f1': array([       nan, 0.54090472,        nan,        nan,        nan,\n",
      "       0.60421336, 0.70883234, 0.70432146, 0.70883234, 0.70883234,\n",
      "       0.70883234, 0.70883234,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.69965211,        nan,        nan,        nan, 0.70471084,\n",
      "       0.71040724, 0.7092145 , 0.71040724, 0.71040724, 0.71040724,\n",
      "       0.71040724,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.70899471,\n",
      "              nan,        nan,        nan, 0.7092145 , 0.71062547,\n",
      "       0.71062547, 0.71062547, 0.71062547, 0.71062547, 0.71062547,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70965309,        nan,\n",
      "              nan,        nan, 0.71013946, 0.71084337, 0.71035782,\n",
      "       0.71084337, 0.71084337, 0.71084337, 0.71084337,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.71035782,        nan,        nan,\n",
      "              nan, 0.71035782, 0.71035782, 0.71035782, 0.71035782,\n",
      "       0.71035782, 0.71035782, 0.71035782,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_f1': array([       nan, 0.57992565,        nan,        nan,        nan,\n",
      "       0.63996517, 0.71224863, 0.70836417, 0.71224863, 0.71224863,\n",
      "       0.7124589 , 0.71224863,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.71114481,        nan,        nan,        nan, 0.71955307,\n",
      "       0.7107681 , 0.71102941, 0.7107681 , 0.7107681 , 0.7107681 ,\n",
      "       0.7107681 ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.71160221,\n",
      "              nan,        nan,        nan, 0.71134021, 0.71060383,\n",
      "       0.71060383, 0.71060383, 0.71060383, 0.71060383, 0.71060383,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.71060383,        nan,\n",
      "              nan,        nan, 0.71060383, 0.71060383, 0.71060383,\n",
      "       0.71060383, 0.71060383, 0.71060383, 0.71060383,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.71060383,        nan,        nan,\n",
      "              nan, 0.71060383, 0.71060383, 0.71060383, 0.71060383,\n",
      "       0.71060383, 0.71060383, 0.71060383,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_f1': array([       nan, 0.58680393,        nan,        nan,        nan,\n",
      "       0.64109347, 0.72057164, 0.71742424, 0.72057164, 0.72057164,\n",
      "       0.72084274, 0.72057164,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.70942813,        nan,        nan,        nan, 0.7158136 ,\n",
      "       0.72030075, 0.71987952, 0.72030075, 0.72030075, 0.72030075,\n",
      "       0.72030075,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.71821954,\n",
      "              nan,        nan,        nan, 0.71912651, 0.71927847,\n",
      "       0.71927847, 0.71927847, 0.71927847, 0.71927847, 0.71927847,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.71927847,        nan,\n",
      "              nan,        nan, 0.71927847, 0.71927847, 0.71927847,\n",
      "       0.71927847, 0.71927847, 0.71927847, 0.71927847,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.71927847,        nan,        nan,\n",
      "              nan, 0.71927847, 0.71927847, 0.71927847, 0.71927847,\n",
      "       0.71927847, 0.71927847, 0.71927847,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split3_test_f1': array([       nan, 0.56484962,        nan,        nan,        nan,\n",
      "       0.60679178, 0.69726859, 0.6924254 , 0.69726859, 0.69726859,\n",
      "       0.69726859, 0.69726859,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.68642746,        nan,        nan,        nan, 0.68997311,\n",
      "       0.69591759, 0.69618321, 0.69591759, 0.69591759, 0.69591759,\n",
      "       0.69591759,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.69495413,\n",
      "              nan,        nan,        nan, 0.69717773, 0.69870328,\n",
      "       0.69770992, 0.69870328, 0.69870328, 0.69870328, 0.69870328,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.69820679,        nan,\n",
      "              nan,        nan, 0.69820679, 0.69870328, 0.69870328,\n",
      "       0.69870328, 0.69870328, 0.69870328, 0.69870328,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.69870328,        nan,        nan,\n",
      "              nan, 0.69870328, 0.69870328, 0.69870328, 0.69870328,\n",
      "       0.69870328, 0.69870328, 0.69870328,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split4_test_f1': array([       nan, 0.57279693,        nan,        nan,        nan,\n",
      "       0.62695925, 0.70199173, 0.69585078, 0.70199173, 0.70199173,\n",
      "       0.70199173, 0.70199173,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.69370413,        nan,        nan,        nan, 0.70011403,\n",
      "       0.69795609, 0.6959818 , 0.69795609, 0.69795609, 0.69795609,\n",
      "       0.69795609,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.69867675,\n",
      "              nan,        nan,        nan, 0.6984127 , 0.6987131 ,\n",
      "       0.6987131 , 0.6987131 , 0.6987131 , 0.6987131 , 0.6987131 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.6987131 ,        nan,\n",
      "              nan,        nan, 0.6987131 , 0.6987131 , 0.6987131 ,\n",
      "       0.6987131 , 0.6987131 , 0.6987131 , 0.6987131 ,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.6987131 ,        nan,        nan,\n",
      "              nan, 0.6987131 , 0.6987131 , 0.6987131 , 0.6987131 ,\n",
      "       0.6987131 , 0.6987131 , 0.6987131 ,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_f1': array([       nan, 0.56905617,        nan,        nan,        nan,\n",
      "       0.62380461, 0.70818259, 0.70367721, 0.70818259, 0.70818259,\n",
      "       0.70827886, 0.70818259,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.70007133,        nan,        nan,        nan, 0.70603293,\n",
      "       0.70706995, 0.70645769, 0.70706995, 0.70706995, 0.70706995,\n",
      "       0.70706995,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.70648947,\n",
      "              nan,        nan,        nan, 0.70705433, 0.70758483,\n",
      "       0.70738616, 0.70758483, 0.70758483, 0.70758483, 0.70758483,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.70729106,        nan,\n",
      "              nan,        nan, 0.70738833, 0.70762841, 0.7075313 ,\n",
      "       0.70762841, 0.70762841, 0.70762841, 0.70762841,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.7075313 ,        nan,        nan,\n",
      "              nan, 0.7075313 , 0.7075313 , 0.7075313 , 0.7075313 ,\n",
      "       0.7075313 , 0.7075313 , 0.7075313 ,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_f1': array([       nan, 0.01585762,        nan,        nan,        nan,\n",
      "       0.01576879, 0.00809797, 0.00893554, 0.00809797, 0.00809797,\n",
      "       0.00820225, 0.00809797,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00934927,        nan,        nan,        nan, 0.01070659,\n",
      "       0.00902558, 0.00920821, 0.00902558, 0.00902558, 0.00902558,\n",
      "       0.00902558,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan, 0.00853362,\n",
      "              nan,        nan,        nan, 0.0082583 , 0.0079081 ,\n",
      "       0.00813788, 0.0079081 , 0.0079081 , 0.0079081 , 0.0079081 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan, 0.00795433,        nan,\n",
      "              nan,        nan, 0.00798554, 0.00792532, 0.00788822,\n",
      "       0.00792532, 0.00792532, 0.00792532, 0.00792532,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.00788822,        nan,        nan,\n",
      "              nan, 0.00788822, 0.00788822, 0.00788822, 0.00788822,\n",
      "       0.00788822, 0.00788822, 0.00788822,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_f1': array([41, 40, 41, 41, 41, 39,  2, 37,  2,  2,  1,  2, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 38, 41, 41, 41, 36, 28, 35, 28, 28,\n",
      "       28, 28, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 34, 41,\n",
      "       41, 41, 33, 11, 26, 11, 11, 11, 11, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41, 41, 41, 41, 41, 27, 41, 41, 41, 25,  6, 16,  6,  6,  6,  6, 41,\n",
      "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 16, 41, 41, 41, 16,\n",
      "       16, 16, 16, 16, 16, 16, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
      "       41])}\n",
      "best score 0.7085307175128996\n",
      "best params{'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "best estimator LogisticRegression(C=0.01, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining the model and training it\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "scoring = [\"accuracy\",\"precision\",\"recall\",\"f1\"]\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, scoring= scoring, refit=\"accuracy\", cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "720 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.70724852        nan        nan        nan 0.70837992\n",
      " 0.70619286 0.706042   0.70619286 0.70619286 0.70619286 0.70619286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70762571        nan        nan        nan 0.70822897\n",
      " 0.70611744 0.70619286 0.70611744 0.70611744 0.70611744 0.70619286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70822917        nan        nan        nan 0.70837983\n",
      " 0.70619289 0.70619289 0.70619289 0.70619289 0.70619289 0.70619289\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70807817        nan        nan        nan 0.70770101\n",
      " 0.7062683  0.706042   0.7062683  0.7062683  0.7062683  0.7062683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70837989        nan        nan        nan 0.70724847\n",
      " 0.7062683  0.70604203 0.7062683  0.7062683  0.7062683  0.7062683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70807817        nan        nan        nan 0.70687122\n",
      " 0.70626827 0.70596659 0.70626827 0.70626827 0.70626827 0.70626827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70800279        nan        nan        nan 0.70717302\n",
      " 0.70626827 0.706042   0.70626827 0.70626827 0.70626827 0.70626827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7080027         nan        nan        nan 0.70739935\n",
      " 0.70626827 0.70596656 0.70626827 0.70626827 0.70626827 0.70626827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70815356        nan        nan        nan 0.70747477\n",
      " 0.70626827 0.70611744 0.70626827 0.70626827 0.70626827 0.70626827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7083799163979785\n",
      "best params{'C': 0.011, 'penalty': 'l1', 'solver': 'saga'}\n",
      "best estimator LogisticRegression(C=0.011, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "# refining the model slightly\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [0.011,0.012,0.013,0.014,0.015,0.016,0.017,0.018,0.019],\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C parameter improved slightly when I tried to focus on numbers closer to 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.48457419        nan        nan        nan 0.51542581\n",
      " 0.69450115 0.69291718 0.69450115 0.69450115 0.69450115 0.69442571\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.69638658        nan        nan        nan 0.69834765\n",
      " 0.70310006 0.70264771 0.70310006 0.70310006 0.70310006 0.70310006\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70491024        nan        nan        nan 0.70611699\n",
      " 0.70521232 0.70506144 0.70528774 0.70528774 0.70521232 0.70528774\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70641922        nan        nan        nan 0.70672096\n",
      " 0.70641922 0.70619294 0.70641922 0.70641922 0.70641922 0.70641922\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70672096        nan        nan        nan 0.70672096\n",
      " 0.70664549 0.70664549 0.70657008 0.70657008 0.70657008 0.70657008\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7067209618954798\n",
      "best params{'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "best estimator LogisticRegression(C=1, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "# Defining the model and training it\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_norm, y_train)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, cv=5)\n",
    "grid_search.fit(X_train_norm, y_train)\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "720 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.7065701         nan        nan        nan 0.70649469\n",
      " 0.70641922 0.70619297 0.70641922 0.70641922 0.70641922 0.70641922\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7065701         nan        nan        nan 0.70664555\n",
      " 0.70634377 0.70626842 0.70634377 0.70634377 0.70634377 0.70634377\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7065701         nan        nan        nan 0.70664555\n",
      " 0.70634377 0.70634383 0.70641919 0.70626833 0.70634377 0.70641919\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7065701         nan        nan        nan 0.70664555\n",
      " 0.70634375 0.70641925 0.70634375 0.70634375 0.70634375 0.70634375\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70657008        nan        nan        nan 0.70664555\n",
      " 0.70641916 0.7063438  0.70634375 0.70634375 0.70634375 0.70634375\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70672096        nan        nan        nan 0.70664555\n",
      " 0.70641916 0.70641922 0.70641916 0.70641916 0.70641916 0.70641916\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70672096        nan        nan        nan 0.70664555\n",
      " 0.7064946  0.70641922 0.70641916 0.70641916 0.70641916 0.70641916\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70679638        nan        nan        nan 0.70672099\n",
      " 0.70641916 0.70641919 0.70641916 0.70641916 0.70641916 0.70641916\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.70679638        nan        nan        nan 0.70672099\n",
      " 0.70657005 0.7064946  0.7064946  0.7064946  0.7064946  0.7064946\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.706796376676777\n",
      "best params{'C': 1.8, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "best estimator LogisticRegression(C=1.8, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_norm, y_train)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9], # Testing hogher C parameters\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, cv=5)\n",
    "grid_search.fit(X_train_norm, y_train)\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time is produced a better result with C parameter as 12 instead. I will now test the second data set to see if it is a better choice for a model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7346303480914171\n",
      "best params{'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "best estimator LogisticRegression(C=0.01, penalty='l1', solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.71562201        nan        nan        nan 0.71524485\n",
      " 0.73244298 0.73342346 0.73244298 0.73244298 0.73244298 0.73244298\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73259378        nan        nan        nan 0.73463035\n",
      " 0.73402697 0.73432858 0.73402697 0.73402697 0.73395153 0.73402697\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73312143        nan        nan        nan 0.73349861\n",
      " 0.73334787 0.73342326 0.73334787 0.73334787 0.73327243 0.73334784\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73327243        nan        nan        nan 0.73327243\n",
      " 0.73319701 0.73319701 0.73319701 0.73319701 0.73319701 0.73319701\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73327243        nan        nan        nan 0.73327243\n",
      " 0.73319698 0.73319698 0.73319698 0.73319698 0.73327243 0.73319698\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defining the model and training it\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_2_scaled, y_train_2)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, cv=5)\n",
    "grid_search.fit(X_train_2_scaled, y_train_2)\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7347055637390028\n",
      "best params{'C': 0.03, 'penalty': 'l1', 'solver': 'saga'}\n",
      "best estimator LogisticRegression(C=0.03, penalty='l1', solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "720 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Sam Glass ITHS\\.virtualenvs\\Machine-learning-NSZCLOcg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.73266919        nan        nan        nan 0.73463035\n",
      " 0.73402697 0.73432858 0.73402697 0.73402697 0.73402697 0.73402697\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73349887        nan        nan        nan 0.73380044\n",
      " 0.73395125 0.73395127 0.73395125 0.73387583 0.7338758  0.73395125\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73327254        nan        nan        nan 0.73470556\n",
      " 0.73372492 0.73357406 0.73372492 0.73372492 0.73372492 0.73372492\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73372511        nan        nan        nan 0.73395119\n",
      " 0.73357409 0.73364956 0.73357409 0.73357409 0.73357409 0.73357409\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73395139        nan        nan        nan 0.73402669\n",
      " 0.73372497 0.73372497 0.73372497 0.73372497 0.73372497 0.73372497\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73357414        nan        nan        nan 0.7336495\n",
      " 0.73380039 0.73380042 0.73380039 0.73380039 0.73380039 0.73380039\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73342328        nan        nan        nan 0.73334776\n",
      " 0.73387583 0.73357409 0.73387583 0.73387583 0.73387583 0.73387583\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73364956        nan        nan        nan 0.73304601\n",
      " 0.73380042 0.73342326 0.73380042 0.73372497 0.73380042 0.73380042\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73349861        nan        nan        nan 0.73334773\n",
      " 0.73357409 0.73342326 0.73357409 0.73357409 0.73357409 0.73357409\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defining the model and training it\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_2_scaled, y_train_2)\n",
    "\n",
    "# defining the hyperparameters I wish to test on the model\n",
    "hyper_param = {\n",
    "    \"C\": [0.01, 0.02, 0.03, 0.04,0.05,0.06,0.07,0.08,0.09],\n",
    "    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\",\"None\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]}\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_param, cv=5)\n",
    "grid_search.fit(X_train_2_scaled, y_train_2)\n",
    "\n",
    "print(f\"best score {grid_search.best_score_}\")\n",
    "print(f\"best params{grid_search.best_params_}\")\n",
    "print(f\"best estimator {grid_search.best_estimator_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-learning-NSZCLOcg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
